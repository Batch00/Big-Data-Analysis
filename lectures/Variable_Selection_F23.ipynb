{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Selection: Best Subset \n",
    "\n",
    "Let's try out the best subset selection algorithm using the baseball salary data we have worked with previously. Our goal is still to predict a playerâ€™s `Salary` using some combination of the performance statistics included in the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Salary  Batting average  On-base percentage  Number of runs  \\\n",
      "0      3300            0.272               0.302              69   \n",
      "1      2600            0.269               0.335              58   \n",
      "2      2500            0.249               0.337              54   \n",
      "3      2475            0.260               0.292              59   \n",
      "4      2313            0.273               0.346              87   \n",
      "..      ...              ...                 ...             ...   \n",
      "332     170            0.111               0.138               3   \n",
      "333     160            0.264               0.318              24   \n",
      "334     142            0.187               0.281              38   \n",
      "335     140            0.264               0.270              24   \n",
      "336     109            0.258               0.395               6   \n",
      "\n",
      "     Number of hits  Number of doubles  Number of triples  \\\n",
      "0               153                 21                  4   \n",
      "1               111                 17                  2   \n",
      "2               115                 15                  1   \n",
      "3               128                 22                  7   \n",
      "4               169                 28                  5   \n",
      "..              ...                ...                ...   \n",
      "332               3                  0                  0   \n",
      "333              48                  7                  0   \n",
      "334              50                  9                  2   \n",
      "335              74                 16                  0   \n",
      "336               8                  1                  0   \n",
      "\n",
      "     Number of home runs  Number of runs batted in  Number of walks  \\\n",
      "0                     31                       104               22   \n",
      "1                     18                        66               39   \n",
      "2                     17                        73               63   \n",
      "3                     12                        50               23   \n",
      "4                      8                        58               70   \n",
      "..                   ...                       ...              ...   \n",
      "332                    0                         1                1   \n",
      "333                    1                        22               15   \n",
      "334                   15                        37               32   \n",
      "335                    3                        27                5   \n",
      "336                    1                         6                7   \n",
      "\n",
      "     Number of strike-outs  Number of stolen bases  Number of errors  \\\n",
      "0                       80                       4                 3   \n",
      "1                       69                       0                 3   \n",
      "2                      116                       6                 5   \n",
      "3                       64                      21                21   \n",
      "4                       53                       3                 8   \n",
      "..                     ...                     ...               ...   \n",
      "332                      7                       0                 0   \n",
      "333                     18                       0                 7   \n",
      "334                     98                       0                 9   \n",
      "335                     42                       0                10   \n",
      "336                     11                       0                 0   \n",
      "\n",
      "     FAeligibility  Indicator of \"free agent in 1991/2\"  \\\n",
      "0                1                                    0   \n",
      "1                1                                    1   \n",
      "2                1                                    0   \n",
      "3                0                                    0   \n",
      "4                0                                    0   \n",
      "..             ...                                  ...   \n",
      "332              0                                    0   \n",
      "333              0                                    0   \n",
      "334              0                                    0   \n",
      "335              0                                    0   \n",
      "336              0                                    0   \n",
      "\n",
      "     Indicator of \"arbitration eligibility\"  \\\n",
      "0                                         0   \n",
      "1                                         0   \n",
      "2                                         0   \n",
      "3                                         1   \n",
      "4                                         1   \n",
      "..                                      ...   \n",
      "332                                       0   \n",
      "333                                       0   \n",
      "334                                       0   \n",
      "335                                       0   \n",
      "336                                       0   \n",
      "\n",
      "     Indicator of \"arbitration in 1991/2\"  \n",
      "0                                       0  \n",
      "1                                       0  \n",
      "2                                       0  \n",
      "3                                       0  \n",
      "4                                       0  \n",
      "..                                    ...  \n",
      "332                                     0  \n",
      "333                                     0  \n",
      "334                                     0  \n",
      "335                                     0  \n",
      "336                                     0  \n",
      "\n",
      "[337 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import itertools\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "url = 'https://www4.stat.ncsu.edu/~boos/var.select/baseball.txt' #download this file using wget and load locally\n",
    "df = pd.read_csv(url)\n",
    "df.rename(columns={'x1': 'Batting average', 'x2': 'On-base percentage', 'x3': 'Number of runs', 'x4': 'Number of hits', 'x5': 'Number of doubles', 'x6': 'Number of triples', 'x7': 'Number of home runs', 'x8': 'Number of runs batted in', 'x9': 'Number of walks', 'x10': 'Number of strike-outs', 'x11': 'Number of stolen bases', 'x12': 'Number of errors', 'x13': 'FAeligibility', 'x14': 'Indicator of \"free agent in 1991/2\"', 'x15': 'Indicator of \"arbitration eligibility\"', 'x16': 'Indicator of \"arbitration in 1991/2\"', 'y': 'Salary'}, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values: Salary                                    0\n",
      "Batting average                           0\n",
      "On-base percentage                        0\n",
      "Number of runs                            0\n",
      "Number of hits                            0\n",
      "Number of doubles                         0\n",
      "Number of triples                         0\n",
      "Number of home runs                       0\n",
      "Number of runs batted in                  0\n",
      "Number of walks                           0\n",
      "Number of strike-outs                     0\n",
      "Number of stolen bases                    0\n",
      "Number of errors                          0\n",
      "FAeligibility                             0\n",
      "Indicator of \"free agent in 1991/2\"       0\n",
      "Indicator of \"arbitration eligibility\"    0\n",
      "Indicator of \"arbitration in 1991/2\"      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of null values:\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of original data: (337, 17)\n"
     ]
    }
   ],
   "source": [
    "# Print the dimensions of the data (337 rows x 17 columns)\n",
    "print(\"Dimensions of original data:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have measurements along every dimension for each observational unit. That is good news - less cleaning and more analyzing! We can now move on to immediately apply the best subset selection algorithm. This algorithm will identify the 'best' model  containing a specified number of predictors. How 'best' is quantified is up to the user. It could be decided according to  $\\bar{R^2}$, AIC, BIC, or RSS. To start we will use RSS as our metric. We can also define a helper function that will generate the best set of variables for each model size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = df.Salary\n",
    "\n",
    "# Drop the column with the independent variable (Salary)\n",
    "X = df.drop(['Salary'], axis=1).astype('float64')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSubset(feature_set):\n",
    "    # Fit model on feature_set and calculate RSS\n",
    "    model = sm.OLS(y,X[list(feature_set)])\n",
    "    regr = model.fit()\n",
    "    RSS = ((regr.predict(X[list(feature_set)]) - y) ** 2).sum()\n",
    "    return {\"model\":regr, \"RSS\":RSS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(feature_set):\n",
    "    # Fit model on feature_set and calculate aic\n",
    "    model = sm.OLS(y,X[list(feature_set)])\n",
    "    regr = model.fit()\n",
    "    return {\"model\":regr, \"AIC\":regr.aic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batting average   -150.802471\n",
       "Number of runs      27.566824\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(y,X[['Batting average','Number of runs']])\n",
    "regr = model.fit()\n",
    "regr.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBest(k):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(X.columns, k):\n",
    "        results.append(processSubset(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the smallest RSS\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed\", models.shape[0], \"models on\", k, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBested(k):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(X.columns, k):\n",
    "        results.append(process(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the smallest RSS\n",
    "    best_model = models.loc[models['AIC'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed\", models.shape[0], \"models on\", k, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 16 models on 1 predictors in 0.05915427207946777 seconds.\n",
      "Processed 120 models on 2 predictors in 0.2243938446044922 seconds.\n",
      "Processed 560 models on 3 predictors in 1.0157053470611572 seconds.\n",
      "Processed 1820 models on 4 predictors in 3.4091951847076416 seconds.\n",
      "Processed 4368 models on 5 predictors in 8.108511686325073 seconds.\n",
      "Processed 8008 models on 6 predictors in 14.84723949432373 seconds.\n",
      "Processed 11440 models on 7 predictors in 21.991337060928345 seconds.\n",
      "Total elapsed time: 49.86320972442627 seconds.\n"
     ]
    }
   ],
   "source": [
    "models_best = pd.DataFrame(columns=[\"RSS\", \"model\"])\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(1,8):\n",
    "    models_best.loc[i] = getBest(i)\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 16 models on 1 predictors in 0.018270492553710938 seconds.\n",
      "Processed 120 models on 2 predictors in 0.11421751976013184 seconds.\n",
      "Processed 560 models on 3 predictors in 0.5156097412109375 seconds.\n",
      "Processed 1820 models on 4 predictors in 1.6911451816558838 seconds.\n",
      "Processed 4368 models on 5 predictors in 4.715756177902222 seconds.\n",
      "Processed 8008 models on 6 predictors in 8.461341381072998 seconds.\n",
      "Processed 11440 models on 7 predictors in 12.785317182540894 seconds.\n",
      "Total elapsed time: 28.53597068786621 seconds.\n"
     ]
    }
   ],
   "source": [
    "models_bested = pd.DataFrame(columns=[\"RSS\", \"model\"])\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(1,8):\n",
    "    models_bested.loc[i] = getBested(i)\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for k in range(1,17):\n",
    "    for combo in itertools.combinations(X.columns, k):\n",
    "        results.append(process(combo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getBested(2)[\"model\"].summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_best.loc[4, \"model\"].summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! In addition to the verbose output we get when we print the summary to the screen, fitting the OLM also produced many other useful statistics such as $\\bar{R^2}$ , AIC, and BIC. We can examine these to try to select the best overall model. Let's start by looking at  R2  across all our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_best.apply(lambda row: row[1].rsquared_adj, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.rcParams.update({'font.size': 18, 'lines.markersize': 10})\n",
    "\n",
    "# Set up a 2x2 grid so we can look at 4 plots at once\n",
    "plt.subplot(2, 2, 1)\n",
    "\n",
    "# We will now plot a red dot to indicate the model with the largest adjusted R^2 statistic.\n",
    "# The argmax() function can be used to identify the location of the maximum point of a vector\n",
    "plt.plot(models_best[\"RSS\"])\n",
    "plt.xlabel('# Predictors')\n",
    "plt.ylabel('RSS')\n",
    "\n",
    "# We will now plot a red dot to indicate the model with the largest adjusted R^2 statistic.\n",
    "# The argmax() function can be used to identify the location of the maximum point of a vector\n",
    "\n",
    "rsquared_adj = models_best.apply(lambda row: row[1].rsquared_adj, axis=1)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(rsquared_adj)\n",
    "plt.plot(rsquared_adj.argmax(), rsquared_adj.max(), \"or\")\n",
    "plt.xlabel('# Predictors')\n",
    "plt.ylabel('adjusted rsquared')\n",
    "\n",
    "# We'll do the same for AIC and BIC, this time looking for the models with the SMALLEST statistic\n",
    "aic = models_best.apply(lambda row: row[1].aic, axis=1)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(aic)\n",
    "plt.plot(aic.argmin(), aic.min(), \"or\")\n",
    "plt.xlabel('# Predictors')\n",
    "plt.ylabel('AIC')\n",
    "\n",
    "bic = models_best.apply(lambda row: row[1].bic, axis=1)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(bic)\n",
    "plt.plot(bic.argmin(), bic.min(), \"or\")\n",
    "plt.xlabel('# Predictors')\n",
    "plt.ylabel('BIC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Stepwise Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(predictors):\n",
    "\n",
    "    # Pull out predictors we still need to process\n",
    "    remaining_predictors = [p for p in X.columns if p not in predictors]\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for p in remaining_predictors:\n",
    "        results.append(processSubset(predictors+[p]))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed \", models.shape[0], \"models on\", len(predictors)+1, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_fwd = pd.DataFrame(columns=[\"RSS\", \"model\"])\n",
    "\n",
    "tic = time.time()\n",
    "predictors = []\n",
    "\n",
    "for i in range(1,len(X.columns)+1):    \n",
    "    models_fwd.loc[i] = forward(predictors)\n",
    "    predictors = models_fwd.loc[i][\"model\"].model.exog_names\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_fwd.loc[1, \"model\"].summary())\n",
    "print(models_fwd.loc[2, \"model\"].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_best.loc[6, \"model\"].summary())\n",
    "print(models_fwd.loc[6, \"model\"].summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backwards Stepwise Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(predictors):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(predictors, len(predictors)-1):\n",
    "        results.append(processSubset(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed \", models.shape[0], \"models on\", len(predictors)-1, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_bwd = pd.DataFrame(columns=[\"RSS\", \"model\"], index = range(1,len(X.columns)))\n",
    "\n",
    "tic = time.time()\n",
    "predictors = X.columns\n",
    "\n",
    "while(len(predictors) > 1):  \n",
    "    models_bwd.loc[len(predictors)-1] = backward(predictors)\n",
    "    predictors = models_bwd.loc[len(predictors)-1][\"model\"].model.exog_names\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data, the best one-variable through six-variable models are each identical for best subset and forward selection. However, the best seven-variable models identified by forward stepwise selection, backward stepwise selection, and best subset selection are different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------\")\n",
    "print(\"Best Subset:\")\n",
    "print(\"------------\")\n",
    "print(models_best.loc[7, \"model\"].params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------\")\n",
    "print(\"Foward Selection:\")\n",
    "print(\"-----------------\")\n",
    "print(models_fwd.loc[7, \"model\"].params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------------------\")\n",
    "print(\"Backward Selection:\")\n",
    "print(\"-------------------\")\n",
    "print(models_bwd.loc[7, \"model\"].params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
