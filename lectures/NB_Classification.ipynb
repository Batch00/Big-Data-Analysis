{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification\n",
    "\n",
    "Naive Bayes models are simple algorithms that can efficiently classify categorical variables in high-dimensional datasets.This notebook will provide a brief and clear introduction to these tools and will demonstrate the nuts and bolts that make them work. First, some preliminaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithms take their name from Bayes's theorem, which defines conditional probability.\n",
    "$$Bayes Theorem: P(y | X)= \\frac{P(X | y)P(y)}{P(X)}$$\n",
    "\n",
    "If the cool kids are around we read this as:\n",
    "\n",
    "$$ Posterior Probability = \\frac{Likelihood \\times Prior Probability}{Marginal Probability}$$\n",
    "\n",
    "Naive Bayes classification is the process of finding the probability of a particular outcome given a set of feature, which we can write as $P(Outcome|Features)$. According to Bayes's theorem that calculation is\n",
    "\n",
    "$$P(Outcome | Features)= \\frac{P(Features | Outcome)P(Outcome)}{P(Features)}$$\n",
    "\n",
    "Again, for the cool kids:\n",
    "\n",
    "- P(Outcome | Features) is the posterior probability of target given the predictors (features)\n",
    "- P(Outcome) is the prior probability of target (prior to seeing features)\n",
    "- P(Features | Outcome) is the probability of observing the particular set of features given the target\n",
    "- P(Features) is the prior or unconditional probability of the predictors arising  \n",
    "\n",
    "Given two possible outcomes, we can directly compare the two to see which is more probable.\n",
    "\n",
    "$$P(Outcome_1 | Features)= \\frac{P(Features | Outcome_1)P(Outcome_1)}{P(Features)}$$\n",
    "\n",
    "$$\\implies P(Features) = \\frac{P(Features | Outcome_1)P(Outcome_1)}{P(Outcome_1 | Features)}$$\n",
    "\n",
    "Thus, it must also be the case that... \n",
    "\n",
    "$$P(Outcome_2 | Features)= \\frac{P(Features | Outcome_2)P(Outcome_2)}{P(Features)}$$\n",
    "\n",
    "$$\\implies P(Features) = \\frac{P(Features | Outcome_2)P(Outcome_2)}{P(Outcome_2 | Features)}$$\n",
    "\n",
    "Meaning...\n",
    "\n",
    "$$ \\frac{P(Features | Outcome_1)P(Outcome_1)}{P(Outcome_1 | Features)} = \\frac{P(Features | Outcome_2)P(Outcome_2)}{P(Outcome_2 | Features)}$$\n",
    "\n",
    "$$ \\implies \\frac{P(Outcome_1 | Features)}{P(Outcome_2 | Features)} = \\frac{P(Features | Outcome_1)P(Outcome_1)} {P(Features | Outcome_2)P(Outcome_2)}$$\n",
    "\n",
    "The ratio of the conditional probabilities is equal to a ratio of the probability of the data given the outcome times the unconditional probability of the outcome. What makes the model \"naive\" are the assumptions about the generative model producing the data associated with each label. \n",
    "\n",
    "The naive bayes probability model assumes that the features are independent, so that \n",
    "\n",
    "$$P(feature_{i}|outcome, feature_{1},...,feature_{i-1}, feature_{i+1},...,feature_{n}) = P(feature_{i}|outcome)$$\n",
    "\n",
    "and accordingly\n",
    "\n",
    "$$P(outcome| feature_{1},...,feature_{n}) = \\frac{P(outcome) \\prod_{i=0}^{n}P(feature_{i}|outcome)}{P(feature_{1},...,feature_{n})}$$\n",
    "\n",
    "The Naive Bayes classifier takes the naive bayes probability model and adds a decision rule - that the more probable outcome (given the features) is picked by the `maximum a posterior` and a class label is predicted via:\n",
    "\n",
    "$$\\hat{outcome} = \\underset{outcome}{\\operatorname{argmax}} P(outcome)\\prod_{i=0}^{n}P(feature_{i}|outcome) $$\n",
    "\n",
    "From an empirical standpoint this is super easy to implement - we just estimate the unconditional probability of the outcome via the frequency with which it occurs in the training dataset. Various naive bayes classifiers differ in the assumptions made about the distribution of $$P(feature_{i} | outcome)$$. With discrete/categorical data it is typically assumed that discrete/categorical values are distributed according to a categorical distribution (this is a generalization of the Bernoulli distribution). \n",
    "\n",
    "The probability of category $t$ in feature $i$ given class $c$ is estimated to be: \n",
    "\n",
    "$$P(feature_{i} = t | outcome = c; \\alpha) = \\frac{N_{tic}+\\alpha}{N_{c} + \\alpha n_{i}}$$\n",
    "\n",
    "That $\\alpha$ is called the Laplace smoothing parameter and it is needed to deal with situations where a particular value does not arise in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\" \n",
    "car_df = pd.read_csv(data, names=['buying','maint','doors','persons','lug_boot','safety','class'], sep=\",\")\n",
    "\n",
    "features = car_df.columns.tolist()\n",
    "features.remove('class')\n",
    "features   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unacc    1210\n",
       "acc       384\n",
       "good       69\n",
       "vgood      65\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has six features and single label. All of the features are strings. To use the naive bayes classifier algorithm we need all of the variables to be coded as integers. The pandas `factorize()` method is useful for this task, as is sklearn's `OrdinalEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 3., 0., 0., 2., 1.],\n",
       "       [3., 3., 0., 0., 2., 2.],\n",
       "       [3., 3., 0., 0., 2., 0.],\n",
       "       ...,\n",
       "       [1., 1., 3., 2., 0., 1.],\n",
       "       [1., 1., 3., 2., 0., 2.],\n",
       "       [1., 1., 3., 2., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "data_encoded = encoder.fit_transform(car_df[features])\n",
    "car_df_encoded = pd.DataFrame(data_encoded, columns=features)\n",
    "data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying  maint  doors  persons  lug_boot  safety\n",
       "0        3.0    3.0    0.0      0.0       2.0     1.0\n",
       "1        3.0    3.0    0.0      0.0       2.0     2.0\n",
       "2        3.0    3.0    0.0      0.0       2.0     0.0\n",
       "3        3.0    3.0    0.0      0.0       1.0     1.0\n",
       "4        3.0    3.0    0.0      0.0       1.0     2.0\n",
       "...      ...    ...    ...      ...       ...     ...\n",
       "1723     1.0    1.0    3.0      2.0       1.0     2.0\n",
       "1724     1.0    1.0    3.0      2.0       1.0     0.0\n",
       "1725     1.0    1.0    3.0      2.0       0.0     1.0\n",
       "1726     1.0    1.0    3.0      2.0       0.0     2.0\n",
       "1727     1.0    1.0    3.0      2.0       0.0     0.0\n",
       "\n",
       "[1728 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety  class\n",
       "0     3.0    3.0    0.0      0.0       2.0     1.0      2\n",
       "1     3.0    3.0    0.0      0.0       2.0     2.0      2\n",
       "2     3.0    3.0    0.0      0.0       2.0     0.0      2\n",
       "3     3.0    3.0    0.0      0.0       1.0     1.0      2\n",
       "4     3.0    3.0    0.0      0.0       1.0     2.0      2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "target_encoded = encoder.fit_transform(car_df['class'])\n",
    "car_df_encoded['class'] = target_encoded\n",
    "encoder.inverse_transform(target_encoded)\n",
    "car_df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying  maint\n",
       "0.0     0.0      108\n",
       "        1.0      108\n",
       "        2.0      108\n",
       "        3.0      108\n",
       "1.0     0.0      108\n",
       "        1.0      108\n",
       "        2.0      108\n",
       "        3.0      108\n",
       "2.0     0.0      108\n",
       "        1.0      108\n",
       "        2.0      108\n",
       "        3.0      108\n",
       "3.0     0.0      108\n",
       "        1.0      108\n",
       "        2.0      108\n",
       "        3.0      108\n",
       "Name: maint, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df_encoded['maint'].groupby(car_df_encoded['buying']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to test that the independence assumption is satisfied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.537474</td>\n",
       "      <td>buying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.522938</td>\n",
       "      <td>maint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.443242</td>\n",
       "      <td>doors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.165404</td>\n",
       "      <td>persons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.290247</td>\n",
       "      <td>lug_boot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.240569</td>\n",
       "      <td>safety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VIF  Features\n",
       "0  2.537474    buying\n",
       "1  2.522938     maint\n",
       "2  2.443242     doors\n",
       "3  2.165404   persons\n",
       "4  2.290247  lug_boot\n",
       "5  2.240569    safety"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"VIF\"] = [variance_inflation_factor(car_df_encoded.values, i) for i in range(len(features))]\n",
    "vif[\"Features\"] = features\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "==============================\n",
      "Misclassified samples: 82\n",
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "#split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(car_df_encoded.drop('class', axis=1), car_df_encoded['class'], test_size=0.3, random_state=143)\n",
    "#fit the model using the training data\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "#check performance\n",
    "prediction = cnb.predict(X_test)\n",
    "probability = cnb.predict_proba(X_test)\n",
    "# how did our model perform?\n",
    "number_wrong = (y_test != prediction).sum()\n",
    "\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 30)\n",
    "print('Misclassified samples: {}'.format(number_wrong))\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Naive Bayes** operates on the assumption of a normal distribution of probabilities. That is to say the feature frequencies are distributed by the Gaussian law:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "The formula is based on the mean (μ) and Bessel corrected variance (σ) of the frequency of each feature in the class of label.\n",
    "\n",
    "**Multinomial Naive Bayes** assumes the distribution of probabilities for each event can be calculated via this formula:\n",
    "\n",
    "$$P(feature_{i} = t | outcome = c; \\alpha) = \\frac{N_{tic}+\\alpha}{N_{c} + \\alpha n_{i}}$$\n",
    "\n",
    "$N_{c}$ is the total number of features of the event i (total number of words in all spam messages), $N_tic$ is a count of each feature, and n is the number of features with α being a Laplace smoothing  parameter to negate the influence of missing types in the training data. \n",
    "\n",
    "**Bernoulli Naive Bayes** is similar to the multinomial approach, but this version works better when the features are a set of boolean values instead of frequencies.\n",
    "\n",
    "$$P(x_i|y) = P(i|y)x_i + (1 - P(i|y))(1-x_i)$$\n",
    "\n",
    "This algorithm penalizes the non-occurrence of a feature while the multinomial approach uses the smoothing parameter for the absent values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import io\n",
    "    \n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'\n",
    "filehandle, _ = urllib.request.urlretrieve(url)\n",
    "zip_file_object = zipfile.ZipFile(filehandle, 'r')\n",
    "first_file = zip_file_object.namelist()[0]\n",
    "file = zip_file_object.open(first_file)\n",
    "content = file.read()\n",
    "\n",
    "df = pd.read_table(io.StringIO(content.decode('utf-8')), names=['label','sms_message'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can't have strings as labels. We need numerical values to input into the algorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion\n",
    "df['label'] = df.label.map({'ham':0, 'spam':1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all looks like nonsense, but it truly is data. 5,572 rows of nonsense data. To turn these text messages into numerical data we need to do some processing. `Bag of Words`(BoW) references classification tasks involving text data. We will take each message and count the frequency of the words in the row. The order of the words is not important, it is just treated as a mixed up 'bag of words'. We will convert these messages into a matrix with a message on each row and every word that appears in the file as a unique column. The cell (row,column) values will count the frequency with which each word occurs in the message. You can find a tool to do this in sklearn - it is the`CountVectorizer` method. Here is an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all',\n",
       " 'along',\n",
       " 'badger',\n",
       " 'be',\n",
       " 'come',\n",
       " 'if',\n",
       " 'it',\n",
       " 'just',\n",
       " 'me',\n",
       " 'on',\n",
       " 'rah',\n",
       " 'said',\n",
       " 'to',\n",
       " 'varsity',\n",
       " 've',\n",
       " 'want',\n",
       " 'when',\n",
       " 'wisconsin',\n",
       " 'with',\n",
       " 'you']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some messages\n",
    "messages = ['On Wisconsin!',\n",
    "                'If you want to be a Badger just come along with me',\n",
    "                'Varsity, Varsity, U-rah-rah! Wisconsin,',\n",
    "                'When you\\'ve said Wisconsin, you\\'ve said it all']\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Import and initialize CountVectorizer \n",
    "count_vector = CountVectorizer()\n",
    "count_vector.fit(messages)\n",
    "features = count_vector.get_feature_names()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 1, 1, 0, 2]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_array = count_vector.transform(messages).toarray()\n",
    "message_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>along</th>\n",
       "      <th>badger</th>\n",
       "      <th>be</th>\n",
       "      <th>come</th>\n",
       "      <th>if</th>\n",
       "      <th>it</th>\n",
       "      <th>just</th>\n",
       "      <th>me</th>\n",
       "      <th>on</th>\n",
       "      <th>rah</th>\n",
       "      <th>said</th>\n",
       "      <th>to</th>\n",
       "      <th>varsity</th>\n",
       "      <th>ve</th>\n",
       "      <th>want</th>\n",
       "      <th>when</th>\n",
       "      <th>wisconsin</th>\n",
       "      <th>with</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   all  along  badger  be  come  if  it  just  me  on  rah  said  to  varsity  \\\n",
       "0    0      0       0   0     0   0   0     0   0   1    0     0   0        0   \n",
       "1    0      1       1   1     1   1   0     1   1   0    0     0   1        0   \n",
       "2    0      0       0   0     0   0   0     0   0   0    2     0   0        2   \n",
       "3    1      0       0   0     0   0   1     0   0   0    0     2   0        0   \n",
       "\n",
       "   ve  want  when  wisconsin  with  you  \n",
       "0   0     0     0          1     0    0  \n",
       "1   0     1     0          0     1    1  \n",
       "2   0     0     0          1     0    0  \n",
       "3   2     0     1          1     0    2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_table = pd.DataFrame(data=message_array, columns=features)\n",
    "freq_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice\n",
    "\n",
    "Now it is your turn to apply the algorithm to the sms message data. \n",
    "\n",
    "1. Split the data into training and testing sets. Use the naming conventions (x_train, x_test, y_train, y_test). Use `train_test_split` from `sklearn.model_selection` as was previously demonstrated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[\"sms_message\"], df[\"label\"], random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a count vector for each word in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the count_vectorizer!\n",
    "count_vector = CountVectorizer()\n",
    "training_data = count_vector.fit_transform(x_train)\n",
    "testing_data = count_vector.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. If you have named things correctly the code above should fit the training that testing data to their respective matricies. Last class we fit the MNLogit model. Today, let's do the same with the MultinomialNB() model. Enter the correct fit command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Recover the predictions from the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = naive_bayes.predict(testing_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculate the quality of your model. There are several measures that we will be interested in. `Accuracy` is the ratio of correct predictions to total predictions (test data points).`Precision` is defined as the number of true positives divided by the sum of both true positives  and false positives. `Recall` is defined as the number of true positives divided by the sum of both true positives  and false negatives. Accuracy is calculated below, read the `sklearn.metrics` page to calculate precision and recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9885139985642498\n",
      "precision score:  0.9720670391061452\n",
      "recall score:  0.9405405405405406\n",
      "f1 score:  0.9560439560439562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "print('precision score: ', format(precision_score(y_test, predictions, pos_label=1)))\n",
    "print('recall score: ', format(recall_score(y_test, predictions, pos_label=1)))\n",
    "print('f1 score: ', format(f1_score(y_test, predictions, pos_label=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
